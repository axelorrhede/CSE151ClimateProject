{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RlMPrVwqOLkI"
   },
   "source": [
    "# ğŸŒ Welcome to the CSE151B Spring 2025 Climate Emulation Competition!\n",
    "\n",
    "Thank you for participating in this exciting challenge focused on building machine learning models to emulate complex climate systems.  \n",
    "This notebook is provided as a **starter template** to help you:\n",
    "\n",
    "- Understand how to load and preprocess the dataset  \n",
    "- Construct a baseline model  \n",
    "- Train and evaluate predictions using a PyTorch Lightning pipeline  \n",
    "- Format your predictions for submission to the leaderboard  \n",
    "\n",
    "You're encouraged to:\n",
    "- Build on this structure or replace it entirely\n",
    "- Try more advanced models and training strategies\n",
    "- Incorporate your own ideas to push the boundaries of what's possible\n",
    "\n",
    "If you're interested in developing within a repository structure and/or use helpful tools like configuration management (based on Hydra) and logging (with Weights & Biases), we recommend checking out the following Github repo. Such a structure can be useful when running multiple experiments and trying various research ideas.\n",
    "\n",
    "ğŸ‘‰ [https://github.com/salvaRC/cse151b-spring2025-competition](https://github.com/salvaRC/cse151b-spring2025-competition)\n",
    "\n",
    "Good luck, have fun, and we hope you learn a lot through this process!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "npNHuN2aS9ut"
   },
   "outputs": [],
   "source": [
    "# run this cell if:\n",
    "# (i) you are running this on colab, and\n",
    "# (ii) have already saved the data on your gdrive.\n",
    "# data is downloaded from kaggle\n",
    "\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "\n",
    "# !cp -r /content/drive/MyDrive/cse151b_data /content/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B4KVND3c_r5D"
   },
   "source": [
    "## Setting up WandB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PSmKEbF-8lpr",
    "outputId": "32d86f78-53d4-4b3f-9d20-c87e3adf3984"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: wandb in ./.local/lib/python3.11/site-packages (0.19.11)\n",
      "Requirement already satisfied: click!=8.0.0,>=7.1 in /opt/conda/lib/python3.11/site-packages (from wandb) (8.1.7)\n",
      "Requirement already satisfied: docker-pycreds>=0.4.0 in ./.local/lib/python3.11/site-packages (from wandb) (0.4.0)\n",
      "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /opt/conda/lib/python3.11/site-packages (from wandb) (3.1.43)\n",
      "Requirement already satisfied: platformdirs in /opt/conda/lib/python3.11/site-packages (from wandb) (4.2.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<7,>=3.19.0 in /opt/conda/lib/python3.11/site-packages (from wandb) (5.29.3)\n",
      "Requirement already satisfied: psutil>=5.0.0 in /opt/conda/lib/python3.11/site-packages (from wandb) (5.9.8)\n",
      "Requirement already satisfied: pydantic<3 in ./.local/lib/python3.11/site-packages (from wandb) (2.11.5)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.11/site-packages (from wandb) (6.0.1)\n",
      "Requirement already satisfied: requests<3,>=2.0.0 in /opt/conda/lib/python3.11/site-packages (from wandb) (2.32.3)\n",
      "Requirement already satisfied: sentry-sdk>=2.0.0 in ./.local/lib/python3.11/site-packages (from wandb) (2.29.1)\n",
      "Requirement already satisfied: setproctitle in ./.local/lib/python3.11/site-packages (from wandb) (1.3.6)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.11/site-packages (from wandb) (69.5.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.4 in ./.local/lib/python3.11/site-packages (from wandb) (4.13.2)\n",
      "Requirement already satisfied: six>=1.4.0 in /opt/conda/lib/python3.11/site-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /opt/conda/lib/python3.11/site-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.11)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in ./.local/lib/python3.11/site-packages (from pydantic<3->wandb) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in ./.local/lib/python3.11/site-packages (from pydantic<3->wandb) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in ./.local/lib/python3.11/site-packages (from pydantic<3->wandb) (0.4.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests<3,>=2.0.0->wandb) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests<3,>=2.0.0->wandb) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests<3,>=2.0.0->wandb) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests<3,>=2.0.0->wandb) (2025.1.31)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /opt/conda/lib/python3.11/site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mjuy021\u001b[0m (\u001b[33mcse151b\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!pip install wandb\n",
    "\n",
    "import wandb\n",
    "wandb.login()\n",
    "# the cell will give you a link (https://wandb.ai/authorize) and pause\n",
    "# click on the link, sign in, copy your API key and paste it in here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "hYlhCCVi_mAH"
   },
   "outputs": [],
   "source": [
    "from pytorch_lightning.loggers import WandbLogger\n",
    "wandb_logger = WandbLogger(\n",
    "    entity=\"cse151b\",                 # our team name on WandB\n",
    "    project=\"climate-project\",        # let's stick to this name\n",
    "    name=\"shitty vit\",                   # CHANGE THIS to whatever you want to identify the run with\n",
    "    log_model=\"all\"                   # logs everything (metrics, hyperparameters, weights)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z7E-MVoHOLkJ"
   },
   "source": [
    "### ğŸ“¦ Install Required Libraries\n",
    "We install the necessary Python packages for data loading, deep learning, and visualization.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "laGcQfROOLkJ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: timm in /opt/conda/lib/python3.11/site-packages (1.0.15)\n",
      "Requirement already satisfied: torch in /opt/conda/lib/python3.11/site-packages (from timm) (2.6.0+cu126)\n",
      "Requirement already satisfied: torchvision in /opt/conda/lib/python3.11/site-packages (from timm) (0.21.0+cu126)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.11/site-packages (from timm) (6.0.1)\n",
      "Requirement already satisfied: huggingface_hub in /opt/conda/lib/python3.11/site-packages (from timm) (0.29.2)\n",
      "Requirement already satisfied: safetensors in /opt/conda/lib/python3.11/site-packages (from timm) (0.5.3)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.11/site-packages (from huggingface_hub->timm) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.11/site-packages (from huggingface_hub->timm) (2024.3.1)\n",
      "Requirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.11/site-packages (from huggingface_hub->timm) (24.0)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.11/site-packages (from huggingface_hub->timm) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /opt/conda/lib/python3.11/site-packages (from huggingface_hub->timm) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in ./.local/lib/python3.11/site-packages (from huggingface_hub->timm) (4.13.2)\n",
      "Requirement already satisfied: sympy==1.13.1 in /opt/conda/lib/python3.11/site-packages (from torch->timm) (1.13.1)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.11/site-packages (from torch->timm) (3.3)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.11/site-packages (from torch->timm) (3.1.3)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /opt/conda/lib/python3.11/site-packages (from torch->timm) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /opt/conda/lib/python3.11/site-packages (from torch->timm) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /opt/conda/lib/python3.11/site-packages (from torch->timm) (12.6.80)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.5.1.17 in /opt/conda/lib/python3.11/site-packages (from torch->timm) (9.5.1.17)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /opt/conda/lib/python3.11/site-packages (from torch->timm) (12.6.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /opt/conda/lib/python3.11/site-packages (from torch->timm) (11.3.0.4)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /opt/conda/lib/python3.11/site-packages (from torch->timm) (10.3.7.77)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /opt/conda/lib/python3.11/site-packages (from torch->timm) (11.7.1.2)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /opt/conda/lib/python3.11/site-packages (from torch->timm) (12.5.4.2)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.3 in /opt/conda/lib/python3.11/site-packages (from torch->timm) (0.6.3)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /opt/conda/lib/python3.11/site-packages (from torch->timm) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /opt/conda/lib/python3.11/site-packages (from torch->timm) (12.6.77)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /opt/conda/lib/python3.11/site-packages (from torch->timm) (12.6.85)\n",
      "Requirement already satisfied: triton==3.2.0 in /opt/conda/lib/python3.11/site-packages (from torch->timm) (3.2.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.11/site-packages (from sympy==1.13.1->torch->timm) (1.3.0)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.11/site-packages (from torchvision->timm) (1.26.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.11/site-packages (from torchvision->timm) (10.4.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.11/site-packages (from jinja2->torch->timm) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests->huggingface_hub->timm) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests->huggingface_hub->timm) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests->huggingface_hub->timm) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests->huggingface_hub->timm) (2025.1.31)\n"
     ]
    }
   ],
   "source": [
    "!pip install xarray zarr dask lightning matplotlib wandb cftime einops --quiet\n",
    "\n",
    "import os\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import dask.array as da\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import lightning.pytorch as pl\n",
    "\n",
    "!pip install timm\n",
    "import timm\n",
    "from einops import rearrange"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ureW0tq0OLkJ"
   },
   "source": [
    "### âš™ï¸ Configuration Setup  \n",
    "Define all model, data, and training hyperparameters in one place for easy control and reproducibility.\n",
    "\n",
    "### ğŸ“Š Data Configuration\n",
    "\n",
    "We define the dataset settings used for training and evaluation. This includes:\n",
    "\n",
    "- **`path`**: Path to the `.zarr` dataset containing monthly climate variables from CMIP6 simulations.\n",
    "- **`input_vars`**: Climate forcing variables (e.g., COâ‚‚, CHâ‚„) used as model inputs.\n",
    "- **`output_vars`**: Target variables to predict â€” surface air temperature (`tas`) and precipitation (`pr`).\n",
    "- **`target_member_id`**: Ensemble member to use from the simulations (each SSP has 3) for target variables.\n",
    "- **`train_ssps`**: SSP scenarios used for training (low to high emissions).\n",
    "- **`test_ssp`**: Scenario held out for evaluation (Must be set to SSP245).\n",
    "- **`test_months`**: Number of months to include in the test split (Must be set to 120).\n",
    "- **`batch_size`** and **`num_workers`**: Data loading parameters for PyTorch training.\n",
    "\n",
    "These settings reflect how the challenge is structured: models must learn from some emission scenarios and generalize to unseen ones.\n",
    "\n",
    "> âš ï¸ **Important:** Do **not modify** the following test settings:\n",
    ">\n",
    "> - `test_ssp` must remain **`ssp245`**, which is the held-out evaluation scenario.\n",
    "> - `test_months` must be **`120`**, corresponding to the last 10 years (monthly resolution) of the scenario.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FTgn9ejc3tX4",
    "outputId": "45d17b4b-3e96-4f4f-a43e-b59a470773de"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = {\n",
    "    \"data\": {\n",
    "        \"path\": \"cse151b_data/processed_data_cse151b_v2_corrupted_ssp245/processed_data_cse151b_v2_corrupted_ssp245.zarr\",\n",
    "        \"input_vars\": [\"CO2\", \"SO2\", \"CH4\", \"BC\", \"rsdt\"],\n",
    "        \"output_vars\": [\"tas\", \"pr\"],\n",
    "        \"target_member_id\": 0,\n",
    "        \"train_ssps\": [\"ssp126\", \"ssp370\", \"ssp585\"],\n",
    "        \"test_ssp\": \"ssp245\",\n",
    "        \"test_months\": 360+12-1,\n",
    "        \"batch_size\": 16,  # Slightly smaller batch due to time dimension\n",
    "        \"num_workers\": 2,\n",
    "    },\n",
    "    \"model\": {\n",
    "        \"type\": \"vit\",\n",
    "        \"patch_size\": 3,\n",
    "        \"dim\": 256,\n",
    "        \"depth\": 4,\n",
    "        \"heads\": 4,\n",
    "        \"seq_len\": 12,\n",
    "    },\n",
    "    \"training\": {\n",
    "        \"lr\": 5e-4,  # try lower if unstable\n",
    "    },\n",
    "    \"trainer\": {\n",
    "        \"max_epochs\": 15,\n",
    "        \"accelerator\": \"auto\",\n",
    "        \"devices\": \"auto\",\n",
    "        \"precision\": 32,\n",
    "        \"deterministic\": True,\n",
    "        \"num_sanity_val_steps\": 0,\n",
    "    },\n",
    "    \"seed\": 42,\n",
    "}\n",
    "pl.seed_everything(config[\"seed\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ezVRccTdOLkK"
   },
   "source": [
    "### ğŸ”§ Spatial Weighting Utility Function\n",
    "\n",
    "This cell sets up utility functions for reproducibility and spatial weighting:\n",
    "\n",
    "- **`get_lat_weights(latitude_values)`**: Computes cosine-based area weights for each latitude, accounting for the Earth's curvature. This is critical for evaluating global climate metrics fairly â€” grid cells near the equator represent larger surface areas than those near the poles.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "OzWjHvI8OLkK"
   },
   "outputs": [],
   "source": [
    "def get_lat_weights(latitude_values):\n",
    "    lat_rad = np.deg2rad(latitude_values)\n",
    "    weights = np.cos(lat_rad)\n",
    "    return weights / np.mean(weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lYRUQmlTOLkK"
   },
   "source": [
    "### ğŸ§  SimpleCNN: A Residual Convolutional Baseline\n",
    "\n",
    "This is a lightweight baseline model designed to capture spatial patterns in global climate data using convolutional layers.\n",
    "\n",
    "- The architecture starts with a **convolution + batch norm + ReLU** block to process the input channels.\n",
    "- It then applies a series of **residual blocks** to extract increasingly abstract spatial features. These help preserve gradient flow during training.\n",
    "- Finally, a few convolutional layers reduce the feature maps down to the desired number of output channels (`tas` and `pr`).\n",
    "\n",
    "This model only serves as a **simple baseline for climate emulation**.\n",
    "\n",
    "We encourage you to build and experiment with your own models and ideas.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_pad(tensor):\n",
    "    \"\"\"\n",
    "    Pads a tensor of shape [B, C, H, W] by:\n",
    "    - Wrapping the last column to the left, and the first column to the right.\n",
    "    - Averaging top two rows for top padding, and bottom two rows for bottom padding.\n",
    "    \"\"\"\n",
    "    B, C, H, W = tensor.shape\n",
    "    # Wrap columns\n",
    "    left_pad = tensor[:, :, :, -1:].clone()  # last column\n",
    "    right_pad = tensor[:, :, :, :1].clone()  # first column\n",
    "    tensor = torch.cat([left_pad, tensor, right_pad], dim=3)  # pad W\n",
    "\n",
    "    # Compute mean over width (dim=3), keeping B and C separate\n",
    "    top_row_mean = tensor[:, :, 0, :].mean(dim=2, keepdim=True)  # shape [B, C, 1]\n",
    "    bottom_row_mean = tensor[:, :, -1, :].mean(dim=2, keepdim=True)  # shape [B, C, 1]\n",
    "    \n",
    "    # Expand to shape [B, C, 1, W] to match row shape\n",
    "    top_pad = top_row_mean.unsqueeze(2).expand(-1, -1, 1, tensor.shape[3])\n",
    "    bottom_pad = bottom_row_mean.unsqueeze(2).expand(-1, -1, 1, tensor.shape[3])\n",
    "    \n",
    "    # Concatenate along height (H) dimension\n",
    "    tensor = torch.cat([top_pad, tensor, bottom_pad], dim=2)\n",
    "    return tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "QbLy95z23RIi"
   },
   "outputs": [],
   "source": [
    "class RowwiseConvLSTMCell(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, height, width, kernel_size=3):\n",
    "        super().__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.height = height\n",
    "\n",
    "        self.scale_up_co2 = nn.Linear(1, height * width)\n",
    "        self.scale_up_ch4 = nn.Linear(1, height * width)\n",
    "\n",
    "        # One convolution per row\n",
    "        self.convs = nn.ModuleList([\n",
    "            nn.Conv2d(\n",
    "                in_channels=input_dim + hidden_dim,\n",
    "                out_channels=4 * hidden_dim,\n",
    "                kernel_size=kernel_size,\n",
    "                padding=0\n",
    "            ) for _ in range(height)\n",
    "        ])\n",
    "\n",
    "    def forward(self, x, h, c):\n",
    "        B, _, H, W = x.shape  # H = height\n",
    "\n",
    "        CO2_scalar = x[:, 0:1, 0, 0]  # shape: [B, 1]\n",
    "        CH4_scalar = x[:, 2:3, 0, 0]\n",
    "\n",
    "        CO2 = self.scale_up_co2(CO2_scalar).view(B, 1, H, W)\n",
    "        CH4 = self.scale_up_ch4(CH4_scalar).view(B, 1, H, W)\n",
    "\n",
    "        SO2 = x[:, 1:2, :, :]\n",
    "        BC = x[:, 3:4, :, :]\n",
    "        rsdt = x[:, 4:, :, :]\n",
    "\n",
    "        x = torch.cat((CO2, SO2, CH4, BC, rsdt), dim=1)\n",
    "        combined = torch.cat([x, h], dim=1)  # shape: [B, C, H, W]\n",
    "\n",
    "        combined = custom_pad(combined)\n",
    "\n",
    "        # Apply row-wise convolutions\n",
    "        outputs = []\n",
    "        for row in range(H):\n",
    "            row_input = combined[:, :, row:row+3, :]  # shape: [B, C, W]\n",
    "            conv_out = self.convs[row](row_input)  # [B, 4*hidden_dim, W]\n",
    "            outputs.append(conv_out)  # [B, 4*hidden_dim, 1, W]\n",
    "        gates = torch.cat(outputs, dim=2)  # [B, 4*hidden_dim, H, W]\n",
    "        i, f, o, g = torch.chunk(gates, 4, dim=1)\n",
    "\n",
    "        i = torch.sigmoid(i)\n",
    "        f = torch.sigmoid(f)\n",
    "        o = torch.sigmoid(o)\n",
    "        g = torch.tanh(g)\n",
    "\n",
    "        c_next = f * c + i * g\n",
    "        h_next = o * torch.tanh(c_next)\n",
    "        return h_next, c_next\n",
    "\n",
    "class ConvLSTMNet(nn.Module):\n",
    "    def __init__(self, n_input_channels, n_output_channels, hidden_dim=64, kernel_size=3, dropout_rate=0.2):\n",
    "        super().__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.conv_lstm = RowwiseConvLSTMCell(n_input_channels, hidden_dim, 48, 72, kernel_size)\n",
    "        self.bn1 = nn.BatchNorm2d(hidden_dim+5)\n",
    "        self.bn2 = nn.BatchNorm2d(hidden_dim)\n",
    "        self.bn3 = nn.BatchNorm2d(hidden_dim)\n",
    "        self.bn4 = nn.BatchNorm2d(hidden_dim)\n",
    "        self.bn5 = nn.BatchNorm2d(hidden_dim)\n",
    "        self.bn6 = nn.BatchNorm1d(hidden_dim)\n",
    "        self.bn7 = nn.BatchNorm1d(hidden_dim)\n",
    "\n",
    "\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.dropout = nn.Dropout2d(dropout_rate)\n",
    "\n",
    "        # self.conv_1 = nn.Conv2d(hidden_dim+5, hidden_dim*8, kernel_size=3, padding=0)\n",
    "        # self.conv_2 = nn.Conv2d(hidden_dim*8, hidden_dim*8, kernel_size=3, padding=0)\n",
    "        # self.conv_3 = nn.Conv2d(hidden_dim*8, hidden_dim*8, kernel_size=3, padding=0)\n",
    "        # self.conv_4 = nn.Conv2d(hidden_dim*8, hidden_dim*8, kernel_size=3, padding=0)\n",
    "        self.convs1 = nn.ModuleList([\n",
    "            nn.Conv2d(\n",
    "                in_channels=hidden_dim+5,\n",
    "                out_channels=hidden_dim,\n",
    "                kernel_size=3,\n",
    "                padding=0\n",
    "            ) for _ in range(48)\n",
    "        ])\n",
    "        self.convs2 = nn.ModuleList([\n",
    "            nn.Conv2d(\n",
    "                in_channels= hidden_dim,\n",
    "                out_channels= hidden_dim,\n",
    "                kernel_size=3,\n",
    "                padding=0\n",
    "            ) for _ in range(48)\n",
    "        ])\n",
    "        self.convs3 = nn.ModuleList([\n",
    "            nn.Conv2d(\n",
    "                in_channels=hidden_dim,\n",
    "                out_channels=hidden_dim,\n",
    "                kernel_size=3,\n",
    "                padding=0\n",
    "            ) for _ in range(48)\n",
    "        ])\n",
    "\n",
    "        self.scale_up_co2 = nn.Linear(hidden_dim, 48 * 72)\n",
    "        self.scale_up_ch4 = nn.Linear(hidden_dim, 48 * 72)\n",
    "        self.scale_up_co2_first = nn.Linear(1, hidden_dim)\n",
    "        self.scale_up_ch4_first = nn.Linear(1, hidden_dim)\n",
    "\n",
    "        self.conv_out = nn.Conv2d(hidden_dim, n_output_channels, kernel_size=1)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: [B, T, C, H, W]\n",
    "        B, T, C, H, W = x.shape\n",
    "        h = torch.zeros(B, self.hidden_dim, H, W, device=x.device)\n",
    "        c = torch.zeros(B, self.hidden_dim, H, W, device=x.device)\n",
    "        for t in range(T):\n",
    "            h, c = self.conv_lstm(x[:, t], h, c)\n",
    "\n",
    "        CO2_scalar = x[:, T-1,0:1, 0, 0]  # shape: [B, 1]\n",
    "        CH4_scalar = x[:, T-1,2:3, 0, 0]\n",
    "        SO2 = x[:, T-1, 1:2, :, :]\n",
    "        BC = x[:, T-1, 3:4, :, :]\n",
    "        rsdt = x[:, T-1, 4:, :, :]\n",
    "\n",
    "        CO2 = self.scale_up_co2_first(CO2_scalar)\n",
    "        CH4 = self.scale_up_ch4_first(CH4_scalar)\n",
    "        \n",
    "        CO2 = self.relu(self.bn6(CO2))\n",
    "        CH4 = self.relu(self.bn7(CH4))\n",
    "\n",
    "        CO2 = self.scale_up_co2(CO2).view(B, 1, H, W)\n",
    "        CH4 = self.scale_up_ch4(CH4).view(B, 1, H, W)\n",
    "\n",
    "        x = torch.cat((CO2, SO2, CH4, BC, rsdt), dim=1)\n",
    "        h = torch.cat([x, h], dim=1)  # shape: [B, C, H, W]\n",
    "\n",
    "\n",
    "        h = self.relu(self.bn1(h))\n",
    "   \n",
    "        h = custom_pad(h)\n",
    "        outputs = []\n",
    "        for row in range(H):\n",
    "            row_input = h[:, :, row:row+3, :]  # shape: [B, C, W]\n",
    "            conv_out = self.convs1[row](row_input)  # [B, 4*hidden_dim, W]\n",
    "            outputs.append(conv_out)\n",
    "        h = torch.cat(outputs, dim=2)\n",
    "\n",
    "        h = self.relu(self.bn2(h))\n",
    "        h = custom_pad(h)\n",
    "        outputs = []\n",
    "        for row in range(H):\n",
    "            row_input = h[:, :, row:row+3, :]  # shape: [B, C, W]\n",
    "            conv_out = self.convs2[row](row_input)  # [B, 4*hidden_dim, W]\n",
    "            outputs.append(conv_out)\n",
    "        h = torch.cat(outputs, dim=2)  # [B, 4*hidden_dim, H, W]\n",
    "\n",
    "        h = self.relu(self.bn4(h))\n",
    "        h = custom_pad(h)\n",
    "        outputs = []\n",
    "        \n",
    "        for row in range(H):\n",
    "            row_input = h[:, :, row:row+3, :]  # shape: [B, C, W]\n",
    "            conv_out = self.convs3[row](row_input)  # [B, 4*hidden_dim, W]\n",
    "            outputs.append(conv_out)\n",
    "        h = torch.cat(outputs, dim=2)\n",
    "\n",
    "        # h = self.relu(self.bn5(h))\n",
    "        # h = custom_pad(h)\n",
    "        # h = self.conv_4(h)\n",
    "        \n",
    "        h = self.relu(self.bn3(h))\n",
    "        h = self.conv_out(h)\n",
    "        return h\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ViTClimateModel(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_channels=5,\n",
    "        output_channels=2,\n",
    "        seq_len=12,\n",
    "        patch_size=3,\n",
    "        dim=256,\n",
    "        depth=4,\n",
    "        heads=4\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.seq_len = seq_len\n",
    "        self.patch_size = patch_size\n",
    "        self.grid_h = 48\n",
    "        self.grid_w = 72\n",
    "        self.dim = dim\n",
    "        self.output_channels = output_channels\n",
    "\n",
    "        self.num_patches_per_frame = (self.grid_h // patch_size) * (self.grid_w // patch_size)\n",
    "        self.total_tokens = seq_len * self.num_patches_per_frame\n",
    "\n",
    "        self.patch_dim = input_channels * patch_size * patch_size\n",
    "\n",
    "        # ğŸ”¹ 3D convolutional stem to enhance local spatiotemporal features\n",
    "        self.stem = nn.Sequential(\n",
    "            nn.Conv3d(input_channels, 32, kernel_size=(3, 3, 3), padding=(1, 1, 1)),\n",
    "            nn.BatchNorm3d(32),\n",
    "            nn.GELU(),\n",
    "            nn.Conv3d(32, input_channels, kernel_size=1)  # back to original channel dim\n",
    "        )\n",
    "\n",
    "        # ğŸ”¹ Normalization before patch projection\n",
    "        self.pre_patch_norm = nn.LayerNorm(self.patch_dim)\n",
    "\n",
    "        # ğŸ”¹ Linear patch embedding\n",
    "        self.patch_to_token = nn.Linear(self.patch_dim, dim)\n",
    "\n",
    "        # ğŸ”¹ CLS token and positional embedding\n",
    "        self.cls_token = nn.Parameter(torch.randn(1, 1, dim))\n",
    "        self.pos_embedding = nn.Parameter(torch.randn(1, self.total_tokens + 1, dim))\n",
    "\n",
    "        # ğŸ”¹ Transformer encoder\n",
    "        self.transformer = nn.TransformerEncoder(\n",
    "            nn.TransformerEncoderLayer(d_model=dim, nhead=heads, dim_feedforward=dim * 4, dropout=0.1),\n",
    "            num_layers=depth\n",
    "        )\n",
    "\n",
    "        self.post_transform_norm = nn.LayerNorm(dim)\n",
    "\n",
    "        # ğŸ”¹ Output head\n",
    "        self.head = nn.Linear(dim, output_channels * patch_size * patch_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x shape: [B, T, C, H, W] â†’ permute â†’ [B, C, T, H, W]\n",
    "        x = x.permute(0, 2, 1, 3, 4)\n",
    "\n",
    "        # Pass through stem\n",
    "        x = self.stem(x)\n",
    "\n",
    "        B, C, T, H, W = x.shape\n",
    "\n",
    "        # Rearrange into patches: [B, T*patches, patch_dim]\n",
    "        x = rearrange(\n",
    "            x, 'b c t (h ph) (w pw) -> b (t h w) (ph pw c)',\n",
    "            ph=self.patch_size,\n",
    "            pw=self.patch_size\n",
    "        )  # â†’ [B, total_tokens, patch_dim]\n",
    "\n",
    "        x = self.pre_patch_norm(x)\n",
    "        x = self.patch_to_token(x)  # â†’ [B, total_tokens, dim]\n",
    "\n",
    "        # Save skip connection\n",
    "        patch_skip = x.clone()\n",
    "\n",
    "        # Add CLS token\n",
    "        cls_token = self.cls_token.expand(B, 1, self.dim)\n",
    "        x = torch.cat((cls_token, x), dim=1)\n",
    "        x = x + self.pos_embedding[:, :x.size(1)]\n",
    "\n",
    "        # Transformer\n",
    "        x = self.transformer(x)\n",
    "        x = self.post_transform_norm(x)\n",
    "\n",
    "        # Remove CLS\n",
    "        x = x[:, 1:]  # [B, total_tokens, dim]\n",
    "\n",
    "        # Residual connection (optional, can comment out to test)\n",
    "        x = x + patch_skip\n",
    "\n",
    "        x = x[:, -self.num_patches_per_frame:]\n",
    "\n",
    "        # Output projection\n",
    "        x = self.head(x)  # [B, total_tokens, output_patch_dim]\n",
    "\n",
    "        # Rearrange back to [B, C, H, W]\n",
    "        x = rearrange(\n",
    "            x,\n",
    "            'b (h w) (c ph pw) -> b c (h ph) (w pw)',\n",
    "            h=self.grid_h // self.patch_size,\n",
    "            w=self.grid_w // self.patch_size,\n",
    "            c=self.output_channels,\n",
    "            ph=self.patch_size,\n",
    "            pw=self.patch_size\n",
    "        )\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qIFGSoH_OLkK"
   },
   "source": [
    "### ğŸ“ Normalizer: Z-Score Scaling for Climate Inputs & Outputs\n",
    "\n",
    "This class handles **Z-score normalization**, a crucial preprocessing step for stable and efficient neural network training:\n",
    "\n",
    "- **`set_input_statistics(mean, std)` / `set_output_statistics(...)`**: Store the mean and standard deviation computed from the training data for later use.\n",
    "- **`normalize(data, data_type)`**: Standardizes the data using `(x - mean) / std`. This is applied separately to inputs and outputs.\n",
    "- **`inverse_transform_output(data)`**: Converts model predictions back to the original physical units (e.g., Kelvin for temperature, mm/day for precipitation).\n",
    "\n",
    "Normalizing the data ensures the model sees inputs with similar dynamic ranges and avoids biases caused by different variable scales.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "iUDIvzSeOLkK"
   },
   "outputs": [],
   "source": [
    "class Normalizer:\n",
    "    def __init__(self):\n",
    "        self.input_means = {}\n",
    "        self.input_stds = {}\n",
    "        self.output_means = {}\n",
    "        self.output_stds = {}\n",
    "\n",
    "    def normalize(self, data, data_type, var):\n",
    "        if data_type == \"input\":\n",
    "            return (data - self.input_means[var]) / self.input_stds[var]\n",
    "        elif data_type == \"output\":\n",
    "            return (data - self.output_means[var]) / self.output_stds[var]\n",
    "\n",
    "    def inverse_transform_output(self, data):\n",
    "        data[:,0,:,:] = data[:,0,:,:] * self.output_stds[\"tas\"] + self.output_means[\"tas\"]\n",
    "        data[:,1,:,:] = data[:,1,:,:] * self.output_stds[\"pr\"] + self.output_means[\"pr\"]\n",
    "        return data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qh2F6jjAOLkL"
   },
   "source": [
    "### ğŸŒ Data Module: Loading, Normalization, and Splitting\n",
    "\n",
    "This section handles the entire data pipeline, from loading the `.zarr` dataset to preparing PyTorch-ready DataLoaders.\n",
    "\n",
    "#### `ClimateDataset`\n",
    "- A simple PyTorch `Dataset` wrapper that preloads the entire (normalized) dataset into memory using Dask.\n",
    "- Converts the data to PyTorch tensors and handles any `NaN` checks up front.\n",
    "\n",
    "#### `ClimateDataModule`\n",
    "A PyTorch Lightning `DataModule` that handles:\n",
    "- âœ… **Loading data** from different SSP scenarios and ensemble members\n",
    "- âœ… **Broadcasting non-spatial inputs** (like COâ‚‚) to match spatial grid size\n",
    "- âœ… **Normalization** using mean/std computed from training data only\n",
    "- âœ… **Splitting** into training, validation, and test sets:\n",
    "  - Training: All months from selected SSPs (except last 10 years of SSP370)\n",
    "  - Validation: Last 10 years (120 months) of SSP370\n",
    "  - Test: Last 10 years of SSP245 (unseen scenario)\n",
    "- âœ… **Batching** and parallelized data loading via PyTorch `DataLoader`s\n",
    "- âœ… **Latitude-based area weighting** for fair climate metric evaluation\n",
    "- Shape of the inputs are Batch_Size X 5 (num_input_variables) X 48 X 72\n",
    "- Shape of ouputputs are Batch_Size X 2 (num_output_variables) X 48 X 72\n",
    "\n",
    "> â„¹ï¸ **Note:** You likely wonâ€™t need to modify this class but feel free to make modifications if you want to inlcude different ensemble mebers to feed more data to your models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "guVhfAQX9Z0Y"
   },
   "outputs": [],
   "source": [
    "class ClimateDataset(Dataset):\n",
    "    def __init__(self, input_array, output_array=None, seq_len=6):\n",
    "        self.seq_len = seq_len\n",
    "        self.inputs = []\n",
    "        self.outputs = [] if output_array is not None else None\n",
    "        self.index_map = []  # maps global index to (chunk_id, local_index)\n",
    "\n",
    "        self.size = 0\n",
    "        for i in range(len(input_array)):\n",
    "            input_tensor = torch.from_numpy(input_array[i]).float()\n",
    "\n",
    "            if output_array is not None:\n",
    "                output_tensor = torch.from_numpy(output_array[i]).float()\n",
    "                if torch.isnan(input_tensor).any() or torch.isnan(output_tensor).any():\n",
    "                    raise ValueError(f\"NaNs found in dataset chunk {i}\")\n",
    "            else:\n",
    "                if torch.isnan(input_tensor).any():\n",
    "                    raise ValueError(f\"NaNs found in input chunk {i}\")\n",
    "                output_tensor = None\n",
    "\n",
    "            num_samples = input_tensor.shape[0] - seq_len + 1\n",
    "            for j in range(num_samples):\n",
    "                self.index_map.append((i, j))\n",
    "\n",
    "            self.inputs.append(input_tensor)\n",
    "            if self.outputs is not None:\n",
    "                self.outputs.append(output_tensor)\n",
    "\n",
    "            self.size += num_samples\n",
    "\n",
    "        print(f\"Creating dataset with {self.size} temporal samples...\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.size\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        i, j = self.index_map[idx]\n",
    "        x_seq = self.inputs[i][j:j + self.seq_len]  # shape: [T, C, H, W]\n",
    "        if self.outputs is not None:\n",
    "            y = self.outputs[i][j + self.seq_len - 1]  # shape: [C, H, W]\n",
    "            return x_seq, y\n",
    "        else:\n",
    "            return x_seq\n",
    "\n",
    "\n",
    "class ClimateDataModule(pl.LightningDataModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        path,\n",
    "        input_vars,\n",
    "        output_vars,\n",
    "        train_ssps,\n",
    "        test_ssp,\n",
    "        target_member_id,\n",
    "        val_split=0.1,\n",
    "        test_months=120,\n",
    "        batch_size=32,\n",
    "        num_workers=0,\n",
    "        seed=42,\n",
    "        seq_len=12,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.path = path\n",
    "        self.input_vars = input_vars\n",
    "        self.output_vars = output_vars\n",
    "        self.train_ssps = train_ssps\n",
    "        self.test_ssp = test_ssp\n",
    "        self.target_member_id = target_member_id\n",
    "        self.val_split = val_split\n",
    "        self.test_months = test_months\n",
    "        self.batch_size = batch_size\n",
    "        self.num_workers = num_workers\n",
    "        self.seed = seed\n",
    "        self.normalizer = Normalizer()\n",
    "        self.seq_len = seq_len\n",
    "\n",
    "    def prepare_data(self):\n",
    "        assert os.path.exists(self.path), f\"Data path not found: {self.path}\"\n",
    "\n",
    "    def setup(self, stage=None):\n",
    "        ds = xr.open_zarr(self.path, consolidated=False, chunks={\"time\": 24})\n",
    "        spatial_template = ds[\"rsdt\"].isel(time=0, ssp=0, drop=True)\n",
    "\n",
    "        def load_ssp(ssp):\n",
    "            input_dask, output_dask = [], []\n",
    "            for var in self.input_vars:\n",
    "                da_var = ds[var].sel(ssp=ssp)\n",
    "                if \"latitude\" in da_var.dims:\n",
    "                    da_var = da_var.rename({\"latitude\": \"y\", \"longitude\": \"x\"})\n",
    "                if \"member_id\" in da_var.dims:\n",
    "                    da_var = da_var.sel(member_id=self.target_member_id)\n",
    "                if set(da_var.dims) == {\"time\"}:\n",
    "                    da_var = da_var.broadcast_like(spatial_template).transpose(\"time\", \"y\", \"x\")\n",
    "                input_dask.append(da_var.data)\n",
    "\n",
    "            for var in self.output_vars:\n",
    "                da_out = ds[var].sel(ssp=ssp, member_id=self.target_member_id)\n",
    "                if \"latitude\" in da_out.dims:\n",
    "                    da_out = da_out.rename({\"latitude\": \"y\", \"longitude\": \"x\"})\n",
    "                output_dask.append(da_out.data)\n",
    "\n",
    "            return da.stack(input_dask, axis=1), da.stack(output_dask, axis=1)\n",
    "\n",
    "        def to_numpy(da_array):\n",
    "            return da_array.compute().astype(np.float32)\n",
    "\n",
    "        def make_numpy(normalized_data):\n",
    "            for i in range(len(normalized_data)):\n",
    "                normalized_data[i] = to_numpy(normalized_data[i])\n",
    "            return normalized_data\n",
    "\n",
    "        def pad_sequence_start(x, pad_len):\n",
    "            pad = np.repeat(x[[0]], pad_len, axis=0)  # Repeat first frame\n",
    "            return np.concatenate([pad, x], axis=0)\n",
    "\n",
    "        train_input, train_output, val_input, val_output = [], [], [], []\n",
    "\n",
    "        for ssp in self.train_ssps:\n",
    "            x, y = load_ssp(ssp)\n",
    "            if ssp == \"ssp370\":\n",
    "                val_input.append(x[-self.test_months:])\n",
    "                val_output.append(y[-self.test_months:])\n",
    "                train_input.append(x[:-self.test_months])\n",
    "                train_output.append(y[:-self.test_months])\n",
    "            else:\n",
    "                train_input.append(x)\n",
    "                train_output.append(y)\n",
    "        train_input_list = train_input\n",
    "        train_output_list = train_output\n",
    "        val_input_list = val_input\n",
    "        val_output_list = val_output\n",
    "        \n",
    "        input_mean = 0.0\n",
    "        input_std = 0.0\n",
    "        \n",
    "        eps = 1e-6  # avoid log(0)\n",
    "        for i in range(len(train_input_list)):\n",
    "            data = train_input_list[i]\n",
    "        \n",
    "            def transform_channels(x):\n",
    "                # x is a NumPy array with shape [samples, channels, height, width]\n",
    "                x1 = x[:, 0:1]  # keep dims\n",
    "                x2 = np.log(x[:, 1:2] + eps)\n",
    "                x3 = x[:, 2:3]\n",
    "                x4 = np.log(x[:, 3:4] + eps)\n",
    "                x5 = x[:, 4:5]\n",
    "                return np.concatenate([x1, x2, x3, x4, x5], axis=1)\n",
    "        \n",
    "            data = data.map_blocks(transform_channels, dtype=data.dtype)\n",
    "            train_input_list[i] = data\n",
    "        \n",
    "            input_mean += da.nanmean(data, axis=(0, 2, 3), keepdims=True).compute()\n",
    "            input_std  += da.nanstd(data, axis=(0, 2, 3), keepdims=True).compute()\n",
    "\n",
    "        input_mean/=3\n",
    "        input_std /=3\n",
    "\n",
    "        input_means = {}\n",
    "        input_stds = {}\n",
    "        for v, var in enumerate(self.input_vars):\n",
    "            input_means[var] = input_mean[0,v,0,0]\n",
    "            input_stds[var] = input_std[0,v,0,0]\n",
    "            \n",
    "        self.normalizer.input_means = input_means\n",
    "        self.normalizer.input_stds = input_stds\n",
    "        \n",
    "        output_mean = 0.0\n",
    "        output_std = 0.0\n",
    "        \n",
    "        for i in range(len(train_output_list)):\n",
    "            output_mean += da.nanmean(train_output_list[i], axis=(0, 2, 3), keepdims=True).compute()\n",
    "            output_std += da.nanstd(train_output_list[i], axis=(0, 2, 3), keepdims=True).compute()\n",
    "        \n",
    "        output_mean /= 3\n",
    "        output_std /= 3\n",
    "\n",
    "        output_means = {}\n",
    "        output_stds = {}\n",
    "        for v, var in enumerate(self.output_vars):\n",
    "            output_means[var] = output_mean[0, v, 0, 0]\n",
    "            output_stds[var] = output_std[0, v, 0, 0]\n",
    "        \n",
    "        self.normalizer.output_means = output_means\n",
    "        self.normalizer.output_stds = output_stds\n",
    "\n",
    "\n",
    "        normalized_train_inputs = []\n",
    "        \n",
    "        for i in range(len(train_input_list)):\n",
    "            data = train_input_list[i]  # shape: [samples, channels, H, W]\n",
    "            var_list = []\n",
    "        \n",
    "            for v, var in enumerate(self.input_vars):\n",
    "                channel_data = data[:, v:v+1, :, :]  # keep shape [samples, 1, H, W]\n",
    "                normed = self.normalizer.normalize(channel_data, \"input\", var)\n",
    "                var_list.append(normed)\n",
    "        \n",
    "            # Concatenate normalized channels back along the channel axis\n",
    "            normalized_data = da.concatenate(var_list, axis=1)  # shape: [samples, channels, H, W]\n",
    "            normalized_train_inputs.append(normalized_data)\n",
    "        \n",
    "        normalized_train_outputs = []\n",
    "        \n",
    "        for i in range(len(train_output_list)):\n",
    "            data = train_output_list[i]\n",
    "            var_list = []\n",
    "        \n",
    "            for v, var in enumerate(self.output_vars):\n",
    "                channel_data = data[:, v:v+1, :, :]\n",
    "                normed = self.normalizer.normalize(channel_data, \"output\", var)\n",
    "                var_list.append(normed)\n",
    "        \n",
    "            normalized_data = da.concatenate(var_list, axis=1)\n",
    "            normalized_train_outputs.append(normalized_data)\n",
    "\n",
    "        normalized_val_inputs = []\n",
    "\n",
    "        for i in range(len(val_input_list)):\n",
    "            data = val_input_list[i]\n",
    "            var_list = []\n",
    "        \n",
    "            for v, var in enumerate(self.input_vars):\n",
    "                channel_data = data[:, v:v+1, :, :]\n",
    "                normed = self.normalizer.normalize(channel_data, \"input\", var)\n",
    "                var_list.append(normed)\n",
    "        \n",
    "            normalized_data = da.concatenate(var_list, axis=1)\n",
    "            normalized_val_inputs.append(normalized_data)\n",
    "\n",
    "        normalized_val_outputs = []\n",
    "\n",
    "        for i in range(len(val_output_list)):\n",
    "            data = val_output_list[i]\n",
    "            var_list = []\n",
    "        \n",
    "            for v, var in enumerate(self.output_vars):\n",
    "                channel_data = data[:, v:v+1, :, :]\n",
    "                normed = self.normalizer.normalize(channel_data, \"output\", var)\n",
    "                var_list.append(normed)\n",
    "        \n",
    "            normalized_data = da.concatenate(var_list, axis=1)\n",
    "            normalized_val_outputs.append(normalized_data)\n",
    "\n",
    "        \n",
    "        test_input, test_output = load_ssp(self.test_ssp)\n",
    "        test_input = test_input[-self.test_months:]\n",
    "        test_output = test_output[-self.test_months:]\n",
    "        test_input_list = [test_input]\n",
    "        test_output_list = [test_output]\n",
    "\n",
    "        normalized_test_inputs=[]\n",
    "        \n",
    "        for i in range(len(test_input_list)):\n",
    "                    data = test_input_list[i]\n",
    "                    var_list = []\n",
    "                \n",
    "                    for v, var in enumerate(self.input_vars):\n",
    "                        channel_data = data[:, v:v+1, :, :]\n",
    "                        normed = self.normalizer.normalize(channel_data, \"input\", var)\n",
    "                        var_list.append(normed)\n",
    "                \n",
    "                    normalized_data = da.concatenate(var_list, axis=1)\n",
    "                    normalized_test_inputs.append(normalized_data)\n",
    "        normalized_test_outputs = []\n",
    "\n",
    "        for i in range(len(test_output_list)):\n",
    "            data = test_output_list[i]\n",
    "            var_list = []\n",
    "        \n",
    "            for v, var in enumerate(self.output_vars):\n",
    "                channel_data = data[:, v:v+1, :, :]\n",
    "                normed = self.normalizer.normalize(channel_data, \"output\", var)\n",
    "                var_list.append(normed)\n",
    "        \n",
    "            normalized_data = da.concatenate(var_list, axis=1)\n",
    "            normalized_test_outputs.append(normalized_data)\n",
    "\n",
    "        \n",
    "        train_input_list = make_numpy(normalized_train_inputs)\n",
    "        train_output_list = make_numpy(normalized_train_outputs)\n",
    "        val_input_list = make_numpy(normalized_val_inputs)\n",
    "        val_output_list = make_numpy(normalized_val_outputs)\n",
    "        test_input_list = make_numpy(normalized_test_inputs)\n",
    "        test_output_list = make_numpy(normalized_test_outputs)\n",
    "\n",
    "        self.train_dataset = ClimateDataset(train_input_list, train_output_list, seq_len=self.seq_len)\n",
    "        self.val_dataset = ClimateDataset(val_input_list, val_output_list, seq_len=self.seq_len)\n",
    "        self.test_dataset = ClimateDataset(test_input_list, test_output_list, seq_len=self.seq_len)\n",
    "\n",
    "        self.lat = spatial_template.y.values\n",
    "        self.lon = spatial_template.x.values\n",
    "        self.area_weights = xr.DataArray(get_lat_weights(self.lat), dims=[\"y\"], coords={\"y\": self.lat})\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.train_dataset, batch_size=self.batch_size, shuffle=True,\n",
    "                          num_workers=self.num_workers, pin_memory=True)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.val_dataset, batch_size=self.batch_size, shuffle=False,\n",
    "                          num_workers=self.num_workers, pin_memory=True)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(self.test_dataset, batch_size=self.batch_size, shuffle=False,\n",
    "                          num_workers=self.num_workers, pin_memory=True)\n",
    "\n",
    "    def get_lat_weights(self):\n",
    "        return self.area_weights\n",
    "\n",
    "    def get_coords(self):\n",
    "        return self.lat, self.lon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(datamodule.test_dataset.outputs[0].shape)\n",
    "# print(datamodule.test_dataset.__getitem__(0)[0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g19Qsq_wOLkL"
   },
   "source": [
    "### âš¡ ClimateEmulationModule: Lightning Wrapper for Climate Model Emulation\n",
    "\n",
    "This is the core model wrapper built with **PyTorch Lightning**, which organizes the training, validation, and testing logic for the climate emulation task. Lightning abstracts away much of the boilerplate code in PyTorch-based deep learning workflows, making it easier to scale models.\n",
    "\n",
    "#### âœ… Key Features\n",
    "\n",
    "- **`training_step` / `validation_step` / `test_step`**: Standard Lightning hooks for computing loss and predictions at each stage. The loss used is **Mean Squared Error (MSE)**.\n",
    "\n",
    "- **Normalization-aware outputs**:\n",
    "  - During validation and testing, predictions and targets are denormalized before evaluation using stored mean/std statistics.\n",
    "  - This ensures evaluation is done in real-world units (Kelvin and mm/day).\n",
    "\n",
    "- **Metric Evaluation** via `_evaluate()`:\n",
    "  For each variable (`tas`, `pr`), it calculates:\n",
    "  - **Monthly Area-Weighted RMSE**\n",
    "  - **Time-Mean RMSE** (RMSE on 10-year average's)\n",
    "  - **Time-Stddev MAE** (MAE on 10-year standard deviation; a measure of temporal variability)\n",
    "    \n",
    "  These metrics reflect the competition's evaluation criteria and are logged and printed.\n",
    "\n",
    "- **Kaggle Submission Writer**:\n",
    "  After testing, predictions are saved to a `.csv` file in the required Kaggle format via `_save_submission()`.\n",
    "\n",
    "- **Saving Predictions for Visualization**:\n",
    "  - Validation predictions are saved tao `val_preds.npy` and `val_trues.npy`\n",
    "  - These can be loaded later for visual inspection of the model's performance.\n",
    "\n",
    " ğŸ”§ **Feel free to modify any part of this module** (loss functions, evaluation, training logic) to better suit your model or training pipeline / Use pure PyTorch etc.\n",
    "\n",
    "âš ï¸ The **final submission `.csv` file must strictly follow the format and naming convention used in `_save_submission()`**, as these `ID`s are used to match predictions to the hidden test set during evaluation.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "l5N_3UKJOLkL"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "class ClimateEmulationModule(pl.LightningModule):\n",
    "    def __init__(self, model, learning_rate=1e-4):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        self.save_hyperparameters(ignore=['model']) # Save all hyperparameters except the model to self.hparams.<param_name>\n",
    "        self.criterion = nn.MSELoss()\n",
    "        self.normalizer = None\n",
    "        self.val_preds, self.val_targets = [], []\n",
    "        self.test_preds, self.test_targets = [], []\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "    def on_fit_start(self):\n",
    "        self.normalizer = self.trainer.datamodule.normalizer  # Get the normalizer from the datamodule (see above)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch # Unpack inputs and targets (this is the output of the _getitem_ method in the Dataset above)\n",
    "        y_hat = self(x)   # Forward pass\n",
    "        mae = nn.functional.l1_loss(y_hat, y)\n",
    "        rmse = torch.sqrt(nn.functional.mse_loss(y_hat, y))\n",
    "        loss = 0.5 * mae + 0.5 * rmse\n",
    "        self.log(\"train/loss\", loss)  # Log loss for tracking\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        loss = self.criterion(y_hat, y)\n",
    "        self.log(\"val/loss\", loss)\n",
    "\n",
    "        y_hat_np = self.normalizer.inverse_transform_output(y_hat.detach().cpu().numpy())\n",
    "        y_np = self.normalizer.inverse_transform_output(y.detach().cpu().numpy())\n",
    "\n",
    "        self.val_preds.append(y_hat_np)\n",
    "        self.val_targets.append(y_np)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def on_validation_epoch_end(self):\n",
    "        # Concatenate all predictions and ground truths from each val step/batch into one array\n",
    "        preds = np.concatenate(self.val_preds, axis=0)\n",
    "        trues = np.concatenate(self.val_targets, axis=0)\n",
    "        self._evaluate(preds, trues, phase=\"val\")\n",
    "        np.save(\"val_preds.npy\", preds)\n",
    "        np.save(\"val_trues.npy\", trues)\n",
    "        self.val_preds.clear()\n",
    "        self.val_targets.clear()\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        y_hat_np = self.normalizer.inverse_transform_output(y_hat.detach().cpu().numpy())\n",
    "        y_np = y.detach().cpu().numpy()\n",
    "\n",
    "        self.test_preds.append(y_hat_np)\n",
    "        self.test_targets.append(y_np)\n",
    "\n",
    "    def on_test_epoch_end(self):\n",
    "        # Concatenate all predictions and ground truths from each test step/batch into one array\n",
    "        preds = np.concatenate(self.test_preds, axis=0)\n",
    "        trues = np.concatenate(self.test_targets, axis=0)\n",
    "        self._evaluate(preds, trues, phase=\"test\")\n",
    "        self._save_submission(preds)\n",
    "        self.test_preds.clear()\n",
    "        self.test_targets.clear()\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return optim.Adam(self.parameters(), lr=self.hparams.learning_rate)\n",
    "        \n",
    "        scheduler = optim.lr_scheduler.StepLR(\n",
    "        optimizer, step_size=10, gamma=0.5 \n",
    "    )\n",
    "\n",
    "    def _evaluate(self, preds, trues, phase=\"val\"):\n",
    "        datamodule = self.trainer.datamodule\n",
    "        area_weights = datamodule.get_lat_weights()\n",
    "        lat, lon = datamodule.get_coords()\n",
    "        time = np.arange(preds.shape[0])\n",
    "        output_vars = datamodule.output_vars\n",
    "\n",
    "        for i, var in enumerate(output_vars):\n",
    "            p = preds[:, i]\n",
    "            t = trues[:, i]\n",
    "            p_xr = xr.DataArray(p, dims=[\"time\", \"y\", \"x\"], coords={\"time\": time, \"y\": lat, \"x\": lon})\n",
    "            t_xr = xr.DataArray(t, dims=[\"time\", \"y\", \"x\"], coords={\"time\": time, \"y\": lat, \"x\": lon})\n",
    "\n",
    "            # RMSE\n",
    "            rmse = np.sqrt(((p_xr - t_xr) ** 2).weighted(area_weights).mean((\"time\", \"y\", \"x\")).item())\n",
    "            # RMSE of time-mean\n",
    "            mean_rmse = np.sqrt(((p_xr.mean(\"time\") - t_xr.mean(\"time\")) ** 2).weighted(area_weights).mean((\"y\", \"x\")).item())\n",
    "            # MAE of time-stddev\n",
    "            std_mae = np.abs(p_xr.std(\"time\") - t_xr.std(\"time\")).weighted(area_weights).mean((\"y\", \"x\")).item()\n",
    "\n",
    "            print(f\"[{phase.upper()}] {var}: RMSE={rmse:.4f}, Time-Mean RMSE={mean_rmse:.4f}, Time-Stddev MAE={std_mae:.4f}\")\n",
    "            self.log_dict({\n",
    "                f\"{phase}/{var}/rmse\": rmse,\n",
    "                f\"{phase}/{var}/time_mean_rmse\": mean_rmse,\n",
    "                f\"{phase}/{var}/time_std_mae\": std_mae,\n",
    "            })\n",
    "\n",
    "    def _save_submission(self, predictions):\n",
    "        datamodule = self.trainer.datamodule\n",
    "        lat, lon = datamodule.get_coords()\n",
    "        output_vars = datamodule.output_vars\n",
    "        time = np.arange(predictions.shape[0])\n",
    "\n",
    "        rows = []\n",
    "        for t_idx, t in enumerate(time):\n",
    "            for var_idx, var in enumerate(output_vars):\n",
    "                for y_idx, y in enumerate(lat):\n",
    "                    for x_idx, x in enumerate(lon):\n",
    "                        row_id = f\"t{t_idx:03d}_{var}_{y:.2f}_{x:.2f}\"\n",
    "                        pred = predictions[t_idx, var_idx, y_idx, x_idx]\n",
    "                        rows.append({\"ID\": row_id, \"Prediction\": pred})\n",
    "\n",
    "        df = pd.DataFrame(rows)\n",
    "        os.makedirs(\"submissions\", exist_ok=True)\n",
    "        filepath = f\"submissions/kaggle_submission_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv\"\n",
    "        df.to_csv(filepath, index=False)\n",
    "        print(f\"âœ… Submission saved to: {filepath}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1s6ju8LLOLkL"
   },
   "source": [
    "### âš¡ Training & Evaluation with PyTorch Lightning\n",
    "\n",
    "This block sets up and runs the training and testing pipeline using **PyTorch Lightningâ€™s `Trainer`**, which abstracts away much of the boilerplate in deep learning workflows.\n",
    "\n",
    "- **Modular Setup**:\n",
    "  - `datamodule`: Handles loading, normalization, and batching of climate data.\n",
    "  - `model`: A convolutional neural network that maps climate forcings to predicted outputs.\n",
    "  - `lightning_module`: Wraps the model with training/validation/test logic and metric evaluation.\n",
    "\n",
    "- **Trainer Flexibility**:\n",
    "  The `Trainer` accepts a wide range of configuration options from `config[\"trainer\"]`, including:\n",
    "  - Number of epochs\n",
    "  - Precision (e.g., 16-bit or 32-bit)\n",
    "  - Device configuration (CPU, GPU, or TPU)\n",
    "  - Determinism, logging, callbacks, and more"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 778,
     "referenced_widgets": [
      "bafc24bdf60540c091fbf88c2da4b3bc",
      "d885fa85852744f0a24766343415b92d",
      "246f739fcce140738bc087e0ee4272ea",
      "20af2bdde3124aeb8b609676c14601c6",
      "0f2868d1f1ab4bed9edf6daa3b6893a1",
      "bbc21ba240ec4d46a99adad0b5d99ef6",
      "1e7291854bb14478aa50c19df6f9b432",
      "47856c429e074f58819cedda3b642de7",
      "10e519beb0414792b373a6352bf0fdaf",
      "0cfe30a6c78d44cea3134ff24e21121b",
      "eacb18856ec9406fb425a9051920824d"
     ]
    },
    "id": "5TEch48gOLkL",
    "outputId": "2dd831a8-229b-4860-eafe-9353c41f4171"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/transformer.py:385: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n",
      "Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>./wandb/run-20250601_091713-n6i7fjqy</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/cse151b/climate-project/runs/n6i7fjqy' target=\"_blank\">shitty vit</a></strong> to <a href='https://wandb.ai/cse151b/climate-project' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/cse151b/climate-project' target=\"_blank\">https://wandb.ai/cse151b/climate-project</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/cse151b/climate-project/runs/n6i7fjqy' target=\"_blank\">https://wandb.ai/cse151b/climate-project/runs/n6i7fjqy</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating dataset with 2659 temporal samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating dataset with 360 temporal samples...\n",
      "Creating dataset with 360 temporal samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name      | Type            | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | model     | ViTClimateModel | 4.4 M  | train\n",
      "1 | criterion | MSELoss         | 0      | train\n",
      "------------------------------------------------------\n",
      "4.4 M     Trainable params\n",
      "0         Non-trainable params\n",
      "4.4 M     Total params\n",
      "17.443    Total estimated model params size (MB)\n",
      "53        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed3a8949a130417eb0006ae18e8a9d2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[VAL] tas: RMSE=3.7334, Time-Mean RMSE=2.3242, Time-Stddev MAE=1.3128\n",
      "[VAL] pr: RMSE=2.7989, Time-Mean RMSE=0.6509, Time-Stddev MAE=1.9312\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[VAL] tas: RMSE=2.9282, Time-Mean RMSE=2.0345, Time-Stddev MAE=0.9665\n",
      "[VAL] pr: RMSE=2.5641, Time-Mean RMSE=0.5125, Time-Stddev MAE=1.5810\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[VAL] tas: RMSE=2.4532, Time-Mean RMSE=1.7338, Time-Stddev MAE=0.7015\n",
      "[VAL] pr: RMSE=2.3291, Time-Mean RMSE=0.5965, Time-Stddev MAE=1.2393\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[VAL] tas: RMSE=2.7201, Time-Mean RMSE=2.0854, Time-Stddev MAE=0.7481\n",
      "[VAL] pr: RMSE=2.1949, Time-Mean RMSE=0.5750, Time-Stddev MAE=0.9912\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[VAL] tas: RMSE=1.8263, Time-Mean RMSE=0.9338, Time-Stddev MAE=0.5507\n",
      "[VAL] pr: RMSE=2.2618, Time-Mean RMSE=0.7825, Time-Stddev MAE=0.9952\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[VAL] tas: RMSE=2.0611, Time-Mean RMSE=1.3222, Time-Stddev MAE=0.4880\n",
      "[VAL] pr: RMSE=2.1461, Time-Mean RMSE=0.5953, Time-Stddev MAE=0.9381\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[VAL] tas: RMSE=1.6075, Time-Mean RMSE=0.8637, Time-Stddev MAE=0.3618\n",
      "[VAL] pr: RMSE=2.0151, Time-Mean RMSE=0.3707, Time-Stddev MAE=0.8203\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[VAL] tas: RMSE=1.7436, Time-Mean RMSE=0.9845, Time-Stddev MAE=0.5473\n",
      "[VAL] pr: RMSE=2.0517, Time-Mean RMSE=0.4814, Time-Stddev MAE=0.8914\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[VAL] tas: RMSE=1.5731, Time-Mean RMSE=0.7980, Time-Stddev MAE=0.3433\n",
      "[VAL] pr: RMSE=2.0550, Time-Mean RMSE=0.4892, Time-Stddev MAE=0.8475\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[VAL] tas: RMSE=1.6551, Time-Mean RMSE=0.8498, Time-Stddev MAE=0.4242\n",
      "[VAL] pr: RMSE=2.0274, Time-Mean RMSE=0.4511, Time-Stddev MAE=0.8310\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[VAL] tas: RMSE=1.7660, Time-Mean RMSE=1.0782, Time-Stddev MAE=0.3958\n",
      "[VAL] pr: RMSE=2.0278, Time-Mean RMSE=0.4278, Time-Stddev MAE=0.8155\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[VAL] tas: RMSE=1.5343, Time-Mean RMSE=0.7596, Time-Stddev MAE=0.2676\n",
      "[VAL] pr: RMSE=2.0030, Time-Mean RMSE=0.3747, Time-Stddev MAE=0.6792\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[VAL] tas: RMSE=1.5971, Time-Mean RMSE=0.8039, Time-Stddev MAE=0.3276\n",
      "[VAL] pr: RMSE=2.0140, Time-Mean RMSE=0.4327, Time-Stddev MAE=0.8057\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[VAL] tas: RMSE=1.4813, Time-Mean RMSE=0.7506, Time-Stddev MAE=0.2778\n",
      "[VAL] pr: RMSE=2.0053, Time-Mean RMSE=0.3961, Time-Stddev MAE=0.7871\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[VAL] tas: RMSE=1.6515, Time-Mean RMSE=0.8571, Time-Stddev MAE=0.4522\n",
      "[VAL] pr: RMSE=2.0618, Time-Mean RMSE=0.4980, Time-Stddev MAE=0.8429\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=15` reached.\n"
     ]
    }
   ],
   "source": [
    "datamodule = ClimateDataModule(**config[\"data\"])\n",
    "model_type = config[\"model\"][\"type\"]\n",
    "\n",
    "model = ViTClimateModel(\n",
    "    input_channels=5,\n",
    "    output_channels=2,\n",
    "    seq_len=config[\"model\"][\"seq_len\"],\n",
    "    patch_size=config[\"model\"][\"patch_size\"],\n",
    "    dim=config[\"model\"][\"dim\"],\n",
    "    depth=config[\"model\"][\"depth\"],\n",
    "    heads=config[\"model\"][\"heads\"]\n",
    ")\n",
    "\n",
    "lightning_module = ClimateEmulationModule(model, learning_rate=config[\"training\"][\"lr\"])\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    logger=wandb_logger,\n",
    "    **config[\"trainer\"]\n",
    ")\n",
    "trainer.fit(lightning_module, datamodule=datamodule)   # Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>â–â–â–â–â–â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆ</td></tr><tr><td>train/loss</td><td>â–ˆâ–‡â–…â–…â–…â–„â–ƒâ–„â–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–‚â–â–‚â–‚â–‚â–â–â–‚â–â–‚â–â–â–</td></tr><tr><td>trainer/global_step</td><td>â–â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–…â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆ</td></tr><tr><td>val/loss</td><td>â–ˆâ–†â–„â–ƒâ–ƒâ–‚â–â–â–â–â–â–â–â–â–</td></tr><tr><td>val/pr/rmse</td><td>â–ˆâ–†â–„â–ƒâ–ƒâ–‚â–â–â–â–â–â–â–â–â–‚</td></tr><tr><td>val/pr/time_mean_rmse</td><td>â–†â–ƒâ–…â–„â–ˆâ–…â–â–ƒâ–ƒâ–‚â–‚â–â–‚â–â–ƒ</td></tr><tr><td>val/pr/time_std_mae</td><td>â–ˆâ–†â–„â–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–â–‚â–‚â–‚</td></tr><tr><td>val/tas/rmse</td><td>â–ˆâ–…â–„â–…â–‚â–ƒâ–â–‚â–â–‚â–‚â–â–â–â–‚</td></tr><tr><td>val/tas/time_mean_rmse</td><td>â–ˆâ–‡â–…â–‡â–‚â–„â–‚â–‚â–â–â–‚â–â–â–â–</td></tr><tr><td>val/tas/time_std_mae</td><td>â–ˆâ–†â–„â–„â–ƒâ–‚â–‚â–ƒâ–‚â–‚â–‚â–â–â–â–‚</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>14</td></tr><tr><td>train/loss</td><td>0.27602</td></tr><tr><td>trainer/global_step</td><td>2504</td></tr><tr><td>val/loss</td><td>0.17366</td></tr><tr><td>val/pr/rmse</td><td>2.06178</td></tr><tr><td>val/pr/time_mean_rmse</td><td>0.49802</td></tr><tr><td>val/pr/time_std_mae</td><td>0.84294</td></tr><tr><td>val/tas/rmse</td><td>1.65154</td></tr><tr><td>val/tas/time_mean_rmse</td><td>0.85715</td></tr><tr><td>val/tas/time_std_mae</td><td>0.45224</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">shitty vit</strong> at: <a href='https://wandb.ai/cse151b/climate-project/runs/n6i7fjqy' target=\"_blank\">https://wandb.ai/cse151b/climate-project/runs/n6i7fjqy</a><br> View project at: <a href='https://wandb.ai/cse151b/climate-project' target=\"_blank\">https://wandb.ai/cse151b/climate-project</a><br>Synced 5 W&B file(s), 0 media file(s), 30 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250601_091713-n6i7fjqy/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import wandb\n",
    "\n",
    "# Finish any old run first (optional but recommended)\n",
    "if wandb.run is not None:\n",
    "    wandb.finish()\n",
    "\n",
    "# Create logger\n",
    "wandb_logger = WandbLogger(project=\"climate-project\", name=\"shitty vit\")\n",
    "\n",
    "# # Log parameter count\n",
    "# wandb.init(project=\"climate-project\", resume=\"allow\", reinit=True)\n",
    "# wandb.log({\"parameter_count\": parameter_count})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hyjHIDjIOLkL"
   },
   "source": [
    "# Test model\n",
    "\n",
    "**IMPORTANT:** Please note that the test metrics will be bad because the test targets have been corrupted on the public Kaggle dataset.\n",
    "The purpose of testing below is to generate the Kaggle submission file based on your model's predictions, which you can submit to the competition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "0Fk97EomOLkL"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating dataset with 2659 temporal samples...\n",
      "Creating dataset with 360 temporal samples...\n",
      "Creating dataset with 360 temporal samples...\n"
     ]
    },
    {
     "ename": "UsageError",
     "evalue": "Run (n6i7fjqy) is finished. The call to `_config_callback` will be ignored. Please make sure that you are using an active run.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUsageError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlightning_module\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatamodule\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdatamodule\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py:775\u001b[0m, in \u001b[0;36mTrainer.test\u001b[0;34m(self, model, dataloaders, ckpt_path, verbose, datamodule)\u001b[0m\n\u001b[1;32m    773\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m=\u001b[39m TrainerStatus\u001b[38;5;241m.\u001b[39mRUNNING\n\u001b[1;32m    774\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtesting \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 775\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_and_handle_interrupt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    776\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_test_impl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatamodule\u001b[49m\n\u001b[1;32m    777\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/lightning/pytorch/trainer/call.py:48\u001b[0m, in \u001b[0;36m_call_and_handle_interrupt\u001b[0;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mlauncher \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     47\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mlauncher\u001b[38;5;241m.\u001b[39mlaunch(trainer_fn, \u001b[38;5;241m*\u001b[39margs, trainer\u001b[38;5;241m=\u001b[39mtrainer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m---> 48\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtrainer_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _TunerExitException:\n\u001b[1;32m     51\u001b[0m     _call_teardown_hook(trainer)\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py:817\u001b[0m, in \u001b[0;36mTrainer._test_impl\u001b[0;34m(self, model, dataloaders, ckpt_path, verbose, datamodule)\u001b[0m\n\u001b[1;32m    813\u001b[0m     download_model_from_registry(ckpt_path, \u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m    814\u001b[0m ckpt_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_checkpoint_connector\u001b[38;5;241m.\u001b[39m_select_ckpt_path(\n\u001b[1;32m    815\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mfn, ckpt_path, model_provided\u001b[38;5;241m=\u001b[39mmodel_provided, model_connected\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    816\u001b[0m )\n\u001b[0;32m--> 817\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mckpt_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    818\u001b[0m \u001b[38;5;66;03m# remove the tensors from the test results\u001b[39;00m\n\u001b[1;32m    819\u001b[0m results \u001b[38;5;241m=\u001b[39m convert_tensors_to_scalars(results)\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py:995\u001b[0m, in \u001b[0;36mTrainer._run\u001b[0;34m(self, model, ckpt_path)\u001b[0m\n\u001b[1;32m    992\u001b[0m     call\u001b[38;5;241m.\u001b[39m_call_callback_hooks(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mon_fit_start\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    993\u001b[0m     call\u001b[38;5;241m.\u001b[39m_call_lightning_module_hook(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mon_fit_start\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 995\u001b[0m \u001b[43m_log_hyperparams\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    997\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mrestore_checkpoint_after_setup:\n\u001b[1;32m    998\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: restoring module and callbacks from checkpoint path: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mckpt_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/lightning/pytorch/loggers/utilities.py:100\u001b[0m, in \u001b[0;36m_log_hyperparams\u001b[0;34m(trainer)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m logger \u001b[38;5;129;01min\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mloggers:\n\u001b[1;32m     99\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m hparams_initial \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 100\u001b[0m         \u001b[43mlogger\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog_hyperparams\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhparams_initial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    101\u001b[0m     logger\u001b[38;5;241m.\u001b[39mlog_graph(pl_module)\n\u001b[1;32m    102\u001b[0m     logger\u001b[38;5;241m.\u001b[39msave()\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/lightning_utilities/core/rank_zero.py:41\u001b[0m, in \u001b[0;36mrank_zero_only.<locals>.wrapped_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe `rank_zero_only.rank` needs to be set before use\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m rank \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m---> 41\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m default\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/pytorch_lightning/loggers/wandb.py:432\u001b[0m, in \u001b[0;36mWandbLogger.log_hyperparams\u001b[0;34m(self, params)\u001b[0m\n\u001b[1;32m    430\u001b[0m params \u001b[38;5;241m=\u001b[39m _sanitize_callable_params(params)\n\u001b[1;32m    431\u001b[0m params \u001b[38;5;241m=\u001b[39m _convert_json_serializable(params)\n\u001b[0;32m--> 432\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexperiment\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_val_change\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/wandb/sdk/wandb_config.py:189\u001b[0m, in \u001b[0;36mConfig.update\u001b[0;34m(self, d, allow_val_change)\u001b[0m\n\u001b[1;32m    187\u001b[0m sanitized \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update(d, allow_val_change)\n\u001b[1;32m    188\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_callback:\n\u001b[0;32m--> 189\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_callback\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msanitized\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/wandb/sdk/wandb_run.py:406\u001b[0m, in \u001b[0;36m_log_to_run.<locals>.wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    403\u001b[0m     run_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_attach_id\n\u001b[1;32m    405\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m wb_logging\u001b[38;5;241m.\u001b[39mlog_to_run(run_id):\n\u001b[0;32m--> 406\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/wandb/sdk/wandb_run.py:472\u001b[0m, in \u001b[0;36m_raise_if_finished.<locals>.wrapper_fn\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    464\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    466\u001b[0m message \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    467\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRun (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mid\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) is finished. The call to\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    468\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m` will be ignored.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    469\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m Please make sure that you are using an active run.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    470\u001b[0m )\n\u001b[0;32m--> 472\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m UsageError(message)\n",
      "\u001b[0;31mUsageError\u001b[0m: Run (n6i7fjqy) is finished. The call to `_config_callback` will be ignored. Please make sure that you are using an active run."
     ]
    }
   ],
   "source": [
    "trainer.test(lightning_module, datamodule=datamodule)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ctl7i3oeOLkL"
   },
   "source": [
    "### Plotting Utils\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8R4yUH_sOLkM"
   },
   "outputs": [],
   "source": [
    "def plot_comparison(true_xr, pred_xr, title, cmap='viridis', diff_cmap='RdBu_r', metric=None):\n",
    "    fig, axs = plt.subplots(1, 3, figsize=(18, 6))\n",
    "\n",
    "    vmin = min(true_xr.min().item(), pred_xr.min().item())\n",
    "    vmax = max(true_xr.max().item(), pred_xr.max().item())\n",
    "\n",
    "    # Ground truth\n",
    "    true_xr.plot(ax=axs[0], cmap=cmap, vmin=vmin, vmax=vmax, add_colorbar=True)\n",
    "    axs[0].set_title(f\"{title} (Ground Truth)\")\n",
    "\n",
    "    # Prediction\n",
    "    pred_xr.plot(ax=axs[1], cmap=cmap, vmin=vmin, vmax=vmax, add_colorbar=True)\n",
    "    axs[1].set_title(f\"{title} (Prediction)\")\n",
    "\n",
    "    # Difference\n",
    "    diff = pred_xr - true_xr\n",
    "    abs_max = np.max(np.abs(diff))\n",
    "    diff.plot(ax=axs[2], cmap=diff_cmap, vmin=-abs_max, vmax=abs_max, add_colorbar=True)\n",
    "    axs[2].set_title(f\"{title} (Difference) {f'- {metric:.4f}' if metric else ''}\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HCnDL0dnOLkM"
   },
   "source": [
    "### ğŸ–¼ï¸ Visualizing Validation Predictions\n",
    "\n",
    "This cell loads saved validation predictions and compares them to the ground truth using spatial plots. These visualizations help you qualitatively assess your model's performance.\n",
    "\n",
    "For each output variable (`tas`, `pr`), we visualize:\n",
    "\n",
    "- **ğŸ“ˆ Time-Mean Map**: The 10-year average spatial pattern for both prediction and ground truth. Helps identify long-term biases or spatial shifts.\n",
    "- **ğŸ“Š Time-Stddev Map**: Shows the standard deviation across time for each grid cell â€” useful for assessing how well the model captures **temporal variability** at each location.\n",
    "- **ğŸ•“ Random Timestep Sample**: Visual comparison of prediction vs ground truth for a single month. Useful for spotting fine-grained anomalies or errors in specific months.\n",
    "\n",
    "> These plots provide intuition beyond metrics and are useful for debugging spatial or temporal model failures.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SU9xBAAgOLkM"
   },
   "outputs": [],
   "source": [
    "# Load validation predictions\n",
    "# make sure to have run the validation loop at least once\n",
    "val_preds = np.load(\"val_preds.npy\")\n",
    "val_trues = np.load(\"val_trues.npy\")\n",
    "\n",
    "lat, lon = datamodule.get_coords()\n",
    "output_vars = datamodule.output_vars\n",
    "time = np.arange(val_preds.shape[0])\n",
    "\n",
    "for i, var in enumerate(output_vars):\n",
    "    pred_xr = xr.DataArray(val_preds[:, i], dims=[\"time\", \"y\", \"x\"], coords={\"time\": time, \"y\": lat, \"x\": lon})\n",
    "    true_xr = xr.DataArray(val_trues[:, i], dims=[\"time\", \"y\", \"x\"], coords={\"time\": time, \"y\": lat, \"x\": lon})\n",
    "\n",
    "    # --- Time Mean ---\n",
    "    plot_comparison(true_xr.mean(\"time\"), pred_xr.mean(\"time\"), f\"{var} Val Time-Mean\")\n",
    "\n",
    "    # --- Time Stddev ---\n",
    "    plot_comparison(true_xr.std(\"time\"), pred_xr.std(\"time\"), f\"{var} Val Time-Stddev\", cmap=\"plasma\")\n",
    "\n",
    "    # --- Random timestep ---\n",
    "    t_idx = np.random.randint(0, len(time))\n",
    "    plot_comparison(true_xr.isel(time=t_idx), pred_xr.isel(time=t_idx), f\"{var} Val Sample Timestep {t_idx}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CmYPDFZ973_J"
   },
   "outputs": [],
   "source": [
    "metrics = pd.read_csv(\"logs/climate/version_13/metrics.csv\")\n",
    "\n",
    "# Drop rows where val/loss is NaN (e.g., training-only steps)\n",
    "train_loss = metrics[metrics[\"train/loss\"].notna()]\n",
    "val_loss = metrics[metrics[\"val/loss\"].notna()]\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(train_loss[\"step\"], train_loss[\"train/loss\"], label=\"Train Loss\")\n",
    "plt.plot(val_loss[\"step\"], val_loss[\"val/loss\"], label=\"Val Loss\")\n",
    "plt.xlabel(\"Step\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Training and Validation Loss over Steps\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2T1FBt6lOLkM"
   },
   "source": [
    "## ğŸ§ª Final Notes\n",
    "\n",
    "This notebook is meant to serve as a **baseline template** â€” a starting point to help you get up and running quickly with the climate emulation challenge.\n",
    "\n",
    "You are **not** required to stick to this exact setup. In fact, we **encourage** you to:\n",
    "\n",
    "- ğŸ” Build on top of the provided `DataModule`.\n",
    "- ğŸ§  Use your own model architectures or training pipelines that youâ€™re more comfortable with\n",
    "- âš—ï¸ Experiment with ideas  \n",
    "- ğŸ¥‡ Compete creatively to climb the Kaggle leaderboard  \n",
    "- ğŸ™Œ Most importantly: **have fun** and **learn as much as you can** along the way\n",
    "\n",
    "This challenge simulates a real-world scientific problem, and thereâ€™s no single \"correct\" approach â€” so be curious, experiment boldly, and make it your own!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "N_txMga3OLkM"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "dockerImageVersionId": 30918,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0cfe30a6c78d44cea3134ff24e21121b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0f2868d1f1ab4bed9edf6daa3b6893a1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": "inline-flex",
      "flex": null,
      "flex_flow": "row wrap",
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "100%"
     }
    },
    "10e519beb0414792b373a6352bf0fdaf": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "1e7291854bb14478aa50c19df6f9b432": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "20af2bdde3124aeb8b609676c14601c6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0cfe30a6c78d44cea3134ff24e21121b",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_eacb18856ec9406fb425a9051920824d",
      "value": "â€‡60/85â€‡[00:09&lt;00:04,â€‡â€‡6.17it/s,â€‡v_num=761y]"
     }
    },
    "246f739fcce140738bc087e0ee4272ea": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_47856c429e074f58819cedda3b642de7",
      "max": 85,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_10e519beb0414792b373a6352bf0fdaf",
      "value": 60
     }
    },
    "47856c429e074f58819cedda3b642de7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": "2",
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bafc24bdf60540c091fbf88c2da4b3bc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_d885fa85852744f0a24766343415b92d",
       "IPY_MODEL_246f739fcce140738bc087e0ee4272ea",
       "IPY_MODEL_20af2bdde3124aeb8b609676c14601c6"
      ],
      "layout": "IPY_MODEL_0f2868d1f1ab4bed9edf6daa3b6893a1"
     }
    },
    "bbc21ba240ec4d46a99adad0b5d99ef6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d885fa85852744f0a24766343415b92d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_bbc21ba240ec4d46a99adad0b5d99ef6",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_1e7291854bb14478aa50c19df6f9b432",
      "value": "Epochâ€‡0:â€‡â€‡71%"
     }
    },
    "eacb18856ec9406fb425a9051920824d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
